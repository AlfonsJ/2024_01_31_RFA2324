{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.3.3c MLP XOR: backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\n",
    "\\boldsymbol{x}&=(x_1,x_2)\\in\\{0, 1\\}^n%\n",
    "&&\\text{donde}\\quad n=2\\\\%\n",
    "\\boldsymbol{z}&=\\mathbf{W}\\boldsymbol{x}+\\boldsymbol{b}_1\\in\\mathbb{R}^{m_1}%\n",
    "&&\\text{donde}\\quad m_1=2,\\,\\mathbf{W}\\in\\mathbb{R}^{m_1\\times n}\\;\\text{y}\\;\\boldsymbol{b}_1\\in\\mathbb{R}^{m_1}\\\\%\n",
    "\\boldsymbol{h}&=\\operatorname{ReLU}(\\boldsymbol{z})\\in\\mathbb{R}^{m_2}%\n",
    "&&\\text{donde}\\quad m_2=2\\\\%\n",
    "\\boldsymbol{a}&=\\mathbf{V}\\boldsymbol{h}+\\boldsymbol{b}_2\\in\\mathbb{R}^{m_3}%\n",
    "&&\\text{donde}\\quad m_3=2,\\,\\mathbf{V}\\in\\mathbb{R}^{m_3\\times m_2}\\;\\text{y}\\;\\boldsymbol{b}_2\\in\\mathbb{R}^{m_3}\\\\%\n",
    "\\hat{\\boldsymbol{y}}&=\\mathcal{S}(\\boldsymbol{a})\\in[0,1]^{m_3}%\n",
    "&&\\text{probabilidades de las clases $0$ y $1$}\\\\%\n",
    "\\mathcal{L}&=\\operatorname{CrossEntropy}(\\boldsymbol{y},\\hat{\\boldsymbol{y}})\\in\\mathbb{R}%\n",
    "&&\\text{salida escalar}\\quad m=1%\n",
    "\\end{align*}$$\n",
    "\n",
    "$$\\mathbf{W}=\\begin{pmatrix}1&1\\\\1&1\\end{pmatrix}\\quad \\boldsymbol{b}_1=\\begin{pmatrix}-1\\\\0.5\\end{pmatrix}\\quad \\mathbf{V}=\\begin{pmatrix}1&-1\\\\-1&1\\end{pmatrix}\\quad\\boldsymbol{b}_2=\\begin{pmatrix}1\\\\-1\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; np.set_printoptions(precision=4)\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[1, 0], [0, 1], [0, 1], [1, 0]])\n",
    "W = np.array([[1, 1], [1, 1]]); b1 = np.array([-1,  .5])\n",
    "V = np.array([[1, -1], [-1, 1]]); b2 = np.array([ 1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward: $\\small\\quad\\boldsymbol{x}\\to\\boldsymbol{z}(\\mathbf{W},\\boldsymbol{b}_1)\\to\\boldsymbol{h}\\to\\boldsymbol{a}(\\mathbf{V},\\boldsymbol{b}_2)\\to\\mathcal{L}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "|$x_1$|$x_2$|$\\boldsymbol{z}=\\mathbf{W}\\boldsymbol{x}+\\boldsymbol{b}_1$|$\\boldsymbol{h}=\\operatorname{ReLU}(\\boldsymbol{z})$|$\\boldsymbol{a}=\\mathbf{V}\\boldsymbol{h}+\\boldsymbol{b}_2$|$\\hat{\\boldsymbol{y}}=\\mathcal{S}(\\boldsymbol{a})$|$-\\boldsymbol{y}^t\\log(\\hat{\\boldsymbol{y}})$|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|$0$|$0$|$(-1, 0.5)^t$|$(0, 0.5)^t$|$(0.5, -0.5)^t$|$(0.7311, 0.2689)^t$|$(0.3133, 0)^t$|\n",
    "|$0$|$1$|$(0, 1.5)^t$ |$(0, 1.5)^t$|$(-0.5, 0.5)^t$|$(0.2689, 0.7311)^t$|$(0, 0.3133)^t$|\n",
    "|$1$|$0$|$(0, 1.5)^t$ |$(0, 1.5)^t$|$(-0.5, 0.5)^t$|$(0.2689, 0.7311)^t$|$(0, 0.3133)^t$|\n",
    "|$1$|$1$|$(1, 2.5)^t$ |$(1, 2.5)^t$|$(-0.5, 0.5)^t$|$(0.2689, 0.7311)^t$|$(1.3133, 0)^t$|\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = [[-1.   0.5], [ 0.   1.5], [ 0.   1.5], [ 1.   2.5]]\n",
      "h = [[0.  0.5], [0.  1.5], [0.  1.5], [1.  2.5]]\n",
      "a = [[ 0.5 -0.5], [-0.5  0.5], [-0.5  0.5], [-0.5  0.5]]\n",
      "y_pred = [[0.7311 0.2689], [0.2689 0.7311], [0.2689 0.7311], [0.2689 0.7311]]\n",
      "Ln = [[ 0.3133 -0.    ], [-0.      0.3133], [-0.      0.3133], [ 1.3133 -0.    ]] \n",
      "L = 0.5632616875182226\n"
     ]
    }
   ],
   "source": [
    "z = X @ W + b1; print('z =', str(z).replace('\\n',','))\n",
    "h = np.maximum(0, z); print('h =', str(h).replace('\\n',','))\n",
    "a = h @ V + b2; print('a =', str(a).replace('\\n',','))\n",
    "y_pred = np.exp(a); y_pred = np.transpose(y_pred.T / y_pred.sum(axis=1))\n",
    "print('y_pred =', str(y_pred).replace('\\n',','))\n",
    "Ln = -y * np.log(y_pred)\n",
    "print('Ln =', str(Ln).replace('\\n',','), '\\nL =', np.sum(Ln)/4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward $\\small\\quad\\mathcal{L}\\to\\boldsymbol{a}(\\mathbf{V},\\boldsymbol{b}_2)\\to\\boldsymbol{h}\\to\\boldsymbol{z}(\\mathbf{W},\\boldsymbol{b}_1)\\to\\boldsymbol{x}$\n",
    "\n",
    "**Paso backward para $\\boldsymbol{x}=(0,0)^t$:** $\\qquad\\boldsymbol{u}_{K+1}=\\boldsymbol{1};\\qquad$**para** $\\;k=K:1:\\quad\\boldsymbol{g}_k=\\boldsymbol{u}_{k+1}^t\\dfrac{\\partial\\boldsymbol{f}(\\boldsymbol{x}_k,\\boldsymbol{\\theta}_k)}{\\partial\\boldsymbol{\\theta}_k}\\quad\\boldsymbol{u}_k^t=\\boldsymbol{u}_{k+1}^t\\dfrac{\\partial\\boldsymbol{f}(\\boldsymbol{x}_k,\\boldsymbol{\\theta}_k)}{\\partial\\boldsymbol{x}_k}$\n",
    "$$\\begin{align*}\n",
    "\\boldsymbol{u}^t%\n",
    "&=1^t\\frac{\\partial\\mathcal{L}}{\\partial\\boldsymbol{a}}%\n",
    "=(\\hat{\\boldsymbol{y}}-\\boldsymbol{y})^t=(0.7311, 0.2689)-(1, 0)=(-0.2689, 0.2689)\\\\%\n",
    "%\n",
    "\\frac{\\partial\\boldsymbol{a}}{\\partial\\mathbf{V}}%\n",
    "&=\\left[\\frac{\\partial a_1}{\\partial\\mathbf{V}}, \\frac{\\partial a_2}{\\partial\\mathbf{V}}\\right]^t%\n",
    "=\\left[\\begin{pmatrix}\\frac{\\partial a_1}{\\partial V_{11}}&\\frac{\\partial a_1}{\\partial V_{12}}\\\\%\n",
    "\\frac{\\partial a_1}{\\partial V_{21}}&\\frac{\\partial a_1}{\\partial V_{22}}\\end{pmatrix},\n",
    "\\begin{pmatrix}\\frac{\\partial a_2}{\\partial V_{11}}&\\frac{\\partial a_2}{\\partial V_{12}}\\\\%\n",
    "\\frac{\\partial a_2}{\\partial V_{21}}&\\frac{\\partial a_2}{\\partial V_{22}}\\end{pmatrix}\\right]^t%\n",
    "=\\left[\\begin{pmatrix}h_1&h_2\\\\0&0\\end{pmatrix},\\begin{pmatrix}0&0\\\\h_1&h_2\\end{pmatrix}\\right]^t\\\\\n",
    "%\n",
    "\\frac{\\partial\\boldsymbol{a}}{\\partial\\boldsymbol{b}_2}%\n",
    "&=\\left[\\frac{\\partial a_1}{\\partial\\boldsymbol{b}_2}, \\frac{\\partial a_2}{\\partial\\boldsymbol{b}_2}\\right]^t%\n",
    "=\\left[\\begin{pmatrix}\\frac{\\partial a_1}{\\partial b_{21}}\\\\\\frac{\\partial a_1}{\\partial b_{22}}\\end{pmatrix},\n",
    "\\begin{pmatrix}\\frac{\\partial a_2}{\\partial b_{21}}\\\\\\frac{\\partial a_2}{\\partial b_{22}}\\end{pmatrix}\\right]^t%\n",
    "=\\left[\\begin{pmatrix}1\\\\0\\end{pmatrix},\\begin{pmatrix}0\\\\1\\end{pmatrix}\\right]^t\\\\\n",
    "%\n",
    "\\boldsymbol{g}_{\\mathbf{V}}%\n",
    "&=\\boldsymbol{u}^t\\frac{\\partial\\boldsymbol{a}}{\\partial\\mathbf{V}}%\n",
    "=(-0.2689, 0.2689)\\left[\\begin{pmatrix}0&0.5\\\\0&0\\end{pmatrix},\\begin{pmatrix}0&0\\\\0&0.5\\end{pmatrix}\\right]^t%\n",
    "=\\begin{pmatrix}0&-0.1345\\\\0&0.1345\\end{pmatrix}\\\\%\n",
    "%\n",
    "\\boldsymbol{g}_{\\boldsymbol{b}_2}%\n",
    "&=\\boldsymbol{u}^t\\frac{\\partial\\boldsymbol{a}}{\\partial\\boldsymbol{b}_2}%\n",
    "=(-0.2689, 0.2689)\\left[\\begin{pmatrix}1\\\\0\\end{pmatrix},\\begin{pmatrix}0\\\\1\\end{pmatrix}\\right]^t%\n",
    "=\\begin{pmatrix}-0.2689\\\\0.2689\\end{pmatrix}\\\\%\n",
    "%\n",
    "\\boldsymbol{u}^t%\n",
    "&=\\boldsymbol{u}^t\\frac{\\partial\\boldsymbol{a}}{\\partial\\boldsymbol{h}}%\n",
    "=(-0.2689, 0.2689)\\mathbf{V}=(-0.5378, 0.5378)\\\\%\n",
    "%\n",
    "\\frac{\\partial\\boldsymbol{h}}{\\partial\\boldsymbol{z}}%\n",
    "&=\\operatorname{diag}(H(\\boldsymbol{z}))%\n",
    "=\\operatorname{diag}(H(-1), H(0.5))%\n",
    "=\\begin{pmatrix}0&0\\\\0&1\\end{pmatrix}\\\\%\n",
    "%\n",
    "\\boldsymbol{u}^t%\n",
    "&=\\boldsymbol{u}^t\\frac{\\partial\\boldsymbol{h}}{\\partial\\boldsymbol{z}}%\n",
    "=(-0.5378, 0.5378)\\begin{pmatrix}0&0\\\\0&1\\end{pmatrix}%\n",
    "=(0, 0.5378)\\\\%\n",
    "%\n",
    "\\frac{\\partial\\boldsymbol{z}}{\\partial\\mathbf{W}}%\n",
    "&=\\left[\\frac{\\partial z_1}{\\partial\\mathbf{W}}, \\frac{\\partial z_2}{\\partial\\mathbf{W}}\\right]^t%\n",
    "=\\left[\\begin{pmatrix}\\frac{\\partial z_1}{\\partial W_{11}}&\\frac{\\partial z_1}{\\partial W_{12}}\\\\%\n",
    "\\frac{\\partial z_1}{\\partial W_{21}}&\\frac{\\partial z_1}{\\partial W_{22}}\\end{pmatrix},\n",
    "\\begin{pmatrix}\\frac{\\partial z_2}{\\partial W_{11}}&\\frac{\\partial z_2}{\\partial W_{12}}\\\\%\n",
    "\\frac{\\partial z_2}{\\partial W_{21}}&\\frac{\\partial z_2}{\\partial W_{22}}\\end{pmatrix}\\right]^t%\n",
    "=\\left[\\begin{pmatrix}x_1&x_2\\\\0&0\\end{pmatrix},\\begin{pmatrix}0&0\\\\x_1&x_2\\end{pmatrix}\\right]^t\\\\%\n",
    "%\n",
    "\\frac{\\partial\\boldsymbol{z}}{\\partial\\boldsymbol{b}_1}%\n",
    "&=\\left[\\frac{\\partial z_1}{\\partial\\boldsymbol{b}_1}, \\frac{\\partial z_2}{\\partial\\boldsymbol{b}_1}\\right]^t%\n",
    "=\\left[\\begin{pmatrix}\\frac{\\partial z_1}{\\partial b_{11}}\\\\\\frac{\\partial z_1}{\\partial b_{12}}\\end{pmatrix},\n",
    "\\begin{pmatrix}\\frac{\\partial z_2}{\\partial b_{11}}\\\\\\frac{\\partial z_2}{\\partial b_{12}}\\end{pmatrix}\\right]^t%\n",
    "=\\left[\\begin{pmatrix}1\\\\0\\end{pmatrix},\\begin{pmatrix}0\\\\1\\end{pmatrix}\\right]^t\\\\%\n",
    "%\n",
    "\\boldsymbol{g}_{\\mathbf{W}}%\n",
    "&=\\boldsymbol{u}^t\\frac{\\partial\\boldsymbol{z}}{\\partial\\mathbf{W}}%\n",
    "=(0, 0.5378)\\left[\\begin{pmatrix}0&0\\\\0&0\\end{pmatrix},\\begin{pmatrix}0&0\\\\0&0\\end{pmatrix}\\right]^t%\n",
    "=\\begin{pmatrix}0&0\\\\0&0\\end{pmatrix}\\\\%\n",
    "%\n",
    "\\boldsymbol{g}_{\\boldsymbol{b}_1}%\n",
    "&=\\boldsymbol{u}^t\\frac{\\partial\\boldsymbol{z}}{\\partial\\boldsymbol{b}_1}%\n",
    "=(0, 0.5378)\\left[\\begin{pmatrix}1\\\\0\\end{pmatrix},\\begin{pmatrix}0\\\\1\\end{pmatrix}\\right]^t%\n",
    "=\\begin{pmatrix}0\\\\0.5378\\end{pmatrix}\\\\%\n",
    "%\n",
    "\\boldsymbol{u}^t%\n",
    "&=\\boldsymbol{u}^t\\frac{\\partial\\boldsymbol{z}}{\\partial\\boldsymbol{x}}%\n",
    "=(0, 0.5378)\\mathbf{W}=(0.5378, 0.5378)%\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uJLa = [[-0.2689  0.2689]]\n",
      "gV = [[-0.     -0.1345], [ 0.      0.1345]]\n",
      "gb2 = [[-0.2689], [ 0.2689]]\n",
      "uJLaJah = [[-0.5379  0.5379]]\n",
      "Jhz = [[0. 0.], [0. 1.]]\n",
      "uJLaJahJhz = [[0.     0.5379]]\n",
      "gW = [[0. 0.], [0. 0.]]\n",
      "gb1 = [[0.    ], [0.5379]]\n",
      "uJLaJahJhzJzx = [[0.5379 0.5379]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 0; ut = (y_pred[n] - y[n]).reshape(1, -1); print('uJLa =', str(ut).replace('\\n',','))\n",
    "gV = np.kron(h[n].reshape(1, -1), ut.T); print('gV =', str(gV).replace('\\n',','))\n",
    "gb2 = ut.T; print('gb2 =', str(gb2).replace('\\n',','))\n",
    "ut = ut @ V; print('uJLaJah =', str(ut).replace('\\n',','))\n",
    "Jhz = np.diag(np.heaviside(z[n], 0.0)); print('Jhz =', str(Jhz).replace('\\n',','))\n",
    "ut = ut @ Jhz; print('uJLaJahJhz =', str(ut).replace('\\n',','))\n",
    "gW = np.kron(X[n, :], ut.T); print('gW =', str(gW).replace('\\n',','))\n",
    "gb1 = ut.T; print('gb1 =', str(gb1).replace('\\n',','))\n",
    "ut = ut @ W; print('uJLaJahJhzJzx =', str(ut).replace('\\n',','), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward-Backward con keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = tf.Tensor([[-1.   0.5] [ 0.   1.5] [ 0.   1.5] [ 1.   2.5]], shape=(4, 2), dtype=float32)\n",
      "h = tf.Tensor([[0.  0.5] [0.  1.5] [0.  1.5] [1.  2.5]], shape=(4, 2), dtype=float32)\n",
      "a = tf.Tensor([[ 0.5 -0.5] [-0.5  0.5] [-0.5  0.5] [-0.5  0.5]], shape=(4, 2), dtype=float32)\n",
      "p = tf.Tensor([[0.7311 0.2689] [0.2689 0.7311] [0.2689 0.7311] [0.2689 0.7311]], shape=(4, 2), dtype=float32)\n",
      "L = tf.Tensor(0.5632617, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.5633 - accuracy: 0.7500\n",
      "[array([[1.0366, 0.9769],\n",
      "       [1.0366, 0.9769]], dtype=float32), array([-0.9634,  0.4769], dtype=float32)] \n",
      " [array([[ 1.0183, -1.0183],\n",
      "       [-0.9711,  0.9711]], dtype=float32), array([ 1.0116, -1.0116], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; from tensorflow import keras\n",
    "W = tf.constant_initializer([[1, 1], [1, 1]]); b1 = tf.constant_initializer([-1,  .5])\n",
    "V = tf.constant_initializer([[1, -1], [-1, 1]]); b2 = tf.constant_initializer([ 1, -1])\n",
    "L1 = keras.layers.Dense(2, activation=tf.nn.relu, input_dim=2, kernel_initializer=W, bias_initializer=b1)\n",
    "L2 = keras.layers.Dense(2, activation=tf.nn.softmax, kernel_initializer=V, bias_initializer=b2)\n",
    "M = keras.Sequential([L1, L2])\n",
    "L1_preact = keras.layers.Dense(2, activation=None, input_dim=2, kernel_initializer=W, bias_initializer=b1)\n",
    "z = L1_preact(X); print('z =', str(z).replace('\\n',''))\n",
    "h = L1(X); print('h =', str(h).replace('\\n',''))\n",
    "L2_preact = keras.layers.Dense(2, activation=None, kernel_initializer=V, bias_initializer=b2)\n",
    "a = L2_preact(h); print('a =', str(a).replace('\\n','')) # softmax\n",
    "p = L2(h); print('p =', str(p).replace('\\n',''))\n",
    "L = tf.keras.losses.CategoricalCrossentropy(from_logits=False); print('L =', L(y, p))\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.1)\n",
    "M.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "M.fit(X, y, epochs=1, verbose=1); print(L1.get_weights(), \"\\n\", L2.get_weights())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemas de clasificación\n",
    "\n",
    "En los problemas de clasificación asumimos que los estados de la naturaleza y acciones son etiquetas de clase:\n",
    "$$\\mathcal{H}=\\mathcal{Y}=\\{1,\\dotsc,C\\}\\qquad\\text{y}\\qquad\\mathcal{A}=\\mathcal{Y}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pérdida 01\n",
    "\n",
    "La pérdida 01 para dos clases, $\\mathcal{Y}=\\{0,1\\}$, aunque directamente generalizable, es:\n",
    "$$\\ell_{01}(y^*,\\hat{y})=\\left[%\n",
    "\\begin{array}{c|cc}\n",
    "    & \\hat{y}=0 & \\hat{y}=1\\\\\\hline%\n",
    "    y^*=0 & 0 & 1\\\\%\n",
    "    y^*=1 & 1 & 0\n",
    "\\end{array}\\right]=\\;\\mathbb{I}(y^*\\neq\\hat{y})$$\n",
    "La **pérdida esperada a posteriori** es la probalidad de error a posteriori, esto es, uno menos la de acertar a posteriori:\n",
    "$$R(\\hat{y}\\mid\\boldsymbol{x})%\n",
    "=\\sum_{y^*}\\ell_{01}(y^*,\\hat{y})\\,p(y^*\\mid\\boldsymbol{x})\n",
    "=\\sum_{y^*\\neq\\hat{y}}p(y^*\\mid\\boldsymbol{x})\n",
    "=1-p(\\hat{y}\\mid\\boldsymbol{x})$$\n",
    "Claramente, el estimador de mínima pérdida esperada es el **estimador máximo a posteriori (MAP),** esto es, la etiqueta más probable o **moda** de la probabilidad a posteriori:\n",
    "$$\\pi(\\boldsymbol{x})=\\operatorname*{argmax}_{y\\in\\mathcal{Y}}\\;p(y\\mid\\boldsymbol{x})$$ \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación sensible al coste\n",
    "\n",
    "Aunque la pérdida 01 es con mucho la más usada, en algunas aplicaciones conviene fijar costes distintos. Consideremos un problema de clasificación binario con función de pérdida general:\n",
    "$$\\ell(y^*,\\hat{y})=\\begin{pmatrix}\n",
    "\\ell_{00} & \\ell_{01}\\\\%\n",
    "\\ell_{10} & \\ell_{11}%\n",
    "\\end{pmatrix}$$\n",
    "Si $p_0=p(y^*=0\\mid\\boldsymbol{x})$ y $p_1=1-p_0$, debemos escoger $\\hat{y}=0$ si su riesgo es menor que el la clase $1$:\n",
    "$$\\ell_{00}\\,p_0+\\ell_{10}\\,p_1<\\ell_{01}\\,p_0+\\ell_{11}\\,p_1$$\n",
    "Si el coste de acertar es nulo, $\\ell_{00}=\\ell_{11}=0$, esta regla de decisión se simplifica como:\n",
    "$$\\ell_{10}\\,p_1<\\ell_{01}(1-p_1)\\quad\\to\\quad p_1<\\frac{\\ell_{01}}{\\ell_{01}+\\ell_{10}}$$\n",
    "Si, además, un falso negativo cuesta $c$ veces más que un falso positivo, $\\ell_{10}=c\\,\\ell_{01}$, entonces esta regla se simplifica aún más:\n",
    "$$p_1<\\frac{1}{1+c}$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

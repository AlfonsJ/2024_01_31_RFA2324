{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición y resultados asintóticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición\n",
    "\n",
    "**Clasificador (por los) $K$ vecinos más próximos o K nearest neighbor (KNN):** $\\;$ dada una entrada $\\boldsymbol{x}$, busca $K$ prototipos (datos) más cercanos a $\\boldsymbol{x}$, $N_K(\\boldsymbol{x},\\mathcal{D})$, y toma sus etiquetas para derivar una distribución sobre las salidas en $\\boldsymbol{x}$:\n",
    "$$p(y=c\\mid\\boldsymbol{x},\\mathcal{D})%\n",
    "=\\frac{1}{K}\\sum_{n\\in N_K(\\boldsymbol{x},\\mathcal{D})}\\mathbb{I}(y_n=c)$$\n",
    "\n",
    "**Clasificador KNN en breve:** $\\;$ retorna la etiqueta más votada (mayoritaria) si es única; si no, en caso de empate a votos entre dos o más clases, devuelve la etiqueta del prototipo más cercano entre los prototipos de las clases empatadas\n",
    "\n",
    "**Clasificador por el vecino más próximo o nearest neighbor (NN):** $\\;$ KNN en el caso particular $K=1$, con función predictiva delta:\n",
    "$$p(y=c\\mid\\boldsymbol{x},\\mathcal{D})=\\delta(c,y_n)%\n",
    "\\quad\\text{con conjunto unitario}\\quad%\n",
    "N_1(\\boldsymbol{x},\\mathcal{D})=\\{n\\}$$\n",
    "\n",
    "**Desempates a distancia decididos al azar:** $\\;$ asumimos que la probabilidad de empate a distancia entre dos prototipos es insignificante por lo que, en caso de dos o más posibles conjuntos de $K$ prototipos más cercanos a $\\boldsymbol{x}$, escogemos uno de ellos al azar\n",
    "\n",
    "**Desempates a votos decididos por el NN:** $\\;$ dado que la probabilidad de empate a votos no es insignificante (por ejemplo con $K=2$), en este caso no decidimos al azar, sino que aplicamos NN entre los prototipos de las clases empatadas\n",
    "\n",
    "**Parámetros principales de KNN:** $\\;$ tamaño del entorno local, $K$, y la distancia $d(\\boldsymbol{x},\\boldsymbol{x}')$ con la que compara cualquier par de puntos en el espacio de representación de los datos, típicamente $\\mathbb{R}^D$\n",
    "\n",
    "**Elección de la función distancia:** $\\;$ se suele usar la Euclídea o, más generalmente, se introduce alguna función con parámetros a aprender; por ejemplo, la distancia de \n",
    "Mahalanobis\n",
    "$$d_M(\\boldsymbol{x},\\boldsymbol{\\mu})=\\sqrt{(\\boldsymbol{x}-\\boldsymbol{\\mu})^tM(\\boldsymbol{x}-\\boldsymbol{\\mu})}%\n",
    "\\quad\\text{con}\\quad M\\succ 0$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados asintóticos\n",
    "\n",
    "**Análisis asintótico:** $\\;$ KNN ha sido objeto de amplio estudio cuando $N\\to\\infty$\n",
    "\n",
    "**NN asintótico:** $\\;$ su error de clasificación no es superior a dos veces el de Bayes\n",
    "\n",
    "**KNN asintótico:** $\\;$ su error converge al de Bayes si $K$ se escoge tal que $K\\to\\infty$ y $K/N\\to 0$; por ejemplo, con $K=\\sqrt{N}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.7.2 BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bidirectional Encoder Representations from Transformers (BERT):** $\\;$ modelo no-causal para representar texto (como ELMo), no generativo, con transformer para transformar una versión modificada de una secuencia de vuelta a su versión no modificada\n",
    "\n",
    "**Tarea fill-in-the-blank o cloze:** $\\;$ la versión modificada omite una palabra o más (texto o palabras cloze) y hay que predecirlas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.7.2.1 Tarea del modelo de lenguaje enmascarado\n",
    "\n",
    "**Ejemplo:** $\\;$ frase de entrenamiento para un modelo de transcripciones de vídeos de cocina\n",
    "<center>\n",
    "\n",
    "`Let's make [MASK] chicken! [SEP] It [MASK] great with orange sauce.` \n",
    "\n",
    "</center>\n",
    "\n",
    "donde `[SEP]` es un token separador entre frases; las etiquetas de salida deseadas para las palabras enmascaradas (cloze) son `some` y `tastes`\n",
    "\n",
    "<div><table border-collapse: collapse><tr>\n",
    "<td style=\"border: none; text-align:left; vertical-align:top; padding:0; margin:0;\" width=600>\n",
    "\n",
    "**Objetivo:** $\\;$ minimización de la log-pseudo-verosimilitud negativa con base en una máscara binaria aleatoria $\\boldsymbol{m}$\n",
    "$$\\mathcal{L}=\\mathbb{E}_{\\boldsymbol{x}\\sim\\mathcal{D}}\\mathbb{E}_{\\boldsymbol{m}}\\sum_{i\\in\\boldsymbol{m}}-\\log p(x_i\\mid \\boldsymbol{x}_{-\\boldsymbol{m}})$$\n",
    "donde la probabilidad del token en la posición $i$, dada la frase enmascarada $\\boldsymbol{x}_{-\\boldsymbol{m}}$, se halla con una softmax, a partir del vector $i$-ésimo de la capa oculta final y los embeddings de los tokens\n",
    "$$p(x_i\\mid\\boldsymbol{x}_{-\\boldsymbol{m}})=\\frac{\\exp(\\boldsymbol{h}(\\boldsymbol{x}_{-\\boldsymbol{m}})_i^t\\,\\boldsymbol{e}(x_i))}{\\sum_{x'}\\exp(\\boldsymbol{h}(\\boldsymbol{x}_{-\\boldsymbol{m}})_i^t\\,\\boldsymbol{e}(x'))}$$\n",
    "\n",
    "</td><td style=\"border: none;\"><img src=\"Figure_15.33_A.png\" width=400></td></tr></table></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.7.2.2 Tarea de predicción de la siguiente frase\n",
    "\n",
    "**Next sentence prediction task:** $\\;$ un objetivo adicional del BERT original consiste en clasificar si una frase sigue a otra\n",
    "$$\\text{CLS} ~ A_1 ~ A_2; \\ldots A_m ; %\n",
    "~\\text{SEP} ~ B_1 ~ B_2; \\ldots; B_n ~ \\text{SEP}%\n",
    "\\qquad\\text{con}\\qquad%\n",
    "\\text{CLS}=1\\text{ si B sigue a A; $0$ si no}$$\n",
    "\n",
    "**Aplicaciones:** $\\;$ tareas de clasificación de pares de frases, como inferencia en lenguaje natural o similitud textual semántica\n",
    "\n",
    "<div><table border-collapse: collapse><tr>\n",
    "<td style=\"border: none; text-align:left; vertical-align:top; padding:0; margin:0;\" width=300>\n",
    "\n",
    "**Entrada:** $\\;$ codificación basada en la suma de tres embeddings\n",
    "* Uno por cada token\n",
    "* Uno por cada etiqueta de segmento\n",
    "* Uno por cada posición\n",
    "\n",
    "</td><td style=\"border: none;\"><img src=\"Figure_15.34.png\" width=700></td></tr></table></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.7.2.3 Fine-tuning BERT para aplicaciones NLP\n",
    "\n",
    "**Fine-tuning BERT:** $\\;$ se añade uno o más cabezales de salida a la capa oculta final para adaptarlo a la tarea deseada\n",
    "\n",
    "<div><table border-collapse: collapse><tr>\n",
    "<td style=\"border: none; text-align:left; vertical-align:top; padding:0; margin:0;\" width=500>\n",
    "\n",
    "**Clasificación de una única frase:** $\\;$ análisis de sentimiento\n",
    "\n",
    "<center><img src=\"Figure_15.35_A.png\" width=450></center>\n",
    "\n",
    "</td><td style=\"border: none; text-align:left; vertical-align:top; padding:0; margin:0;\" width=500>\n",
    "\n",
    "**Clasificación de un par de frases:** $\\;$ inferencia en lenguaje natural\n",
    "\n",
    "<center><img src=\"Figure_15.35_B.png\" width=450></center>\n",
    "\n",
    "</td></tr></table></div>\n",
    "\n",
    "<div><table border-collapse: collapse><tr>\n",
    "<td style=\"border: none; text-align:left; vertical-align:top; padding:0; margin:0;\" width=500>\n",
    "\n",
    "**Etiquetado de frases:** $\\;$ se asocia una etiqueta con cada palabra\n",
    "\n",
    "<center><img src=\"Figure_15.35_C.png\" width=450></center>\n",
    "\n",
    "</td><td style=\"border: none; text-align:left; vertical-align:top; padding:0; margin:0;\" width=500>\n",
    "\n",
    "**Question answering:** $\\;$ búsqueda de respuestas\n",
    "\n",
    "<center><img src=\"Figure_15.35_D.png\" width=450></center>\n",
    "\n",
    "</td></tr></table></div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

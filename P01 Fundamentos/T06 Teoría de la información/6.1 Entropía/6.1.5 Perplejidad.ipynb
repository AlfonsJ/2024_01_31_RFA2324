{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplejidad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición\n",
    "\n",
    "La **perplejidad** de un distribución de probabilidad discreta $p$ es:\n",
    "$$\\operatorname{perplexity}(p)=2^{\\mathbb{H}(p)}$$\n",
    "\n",
    "Se suele interpretar como una medida de **impredecibilidad:**\n",
    "* La impredecibilidad mínima se alcanza con una distribución de entropía nula, por lo que la perplejidad es uno\n",
    "$$\\operatorname{perplexity}(p)=2^0=1$$\n",
    "* La impredecibilidad máxima se da cuando $p$ es uniforme, con entropía $\\log_2 K$ (sobre $K$ estados), por lo que la perplejidad es $K$:\n",
    "$$\\operatorname{perplexity}(p)=2^{\\log_2 K}=K$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplejidad conjunta con la empírica\n",
    "\n",
    "Sea la distribución empírica de los datos $\\mathcal{D}$:\n",
    "$$p_{\\mathcal{D}}(x\\mid\\mathcal{D})=\\frac{1}{N}\\sum_{n=1}^N\\delta_{x_n}(x)$$\n",
    "\n",
    "Dada una distribución $p$, podemos medir cómo de bien predice $\\mathcal{D}$ calculando:\n",
    "$$\\operatorname{perplexity}(p_{\\mathcal{D}},p)=2^{\\mathbb{H}(p_{\\mathcal{D}},p)}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curvas ROC\n",
    "\n",
    "Sea un problema de clasificación en una clase positiva ($1$) y otra negativa ($-1$ o $0$). Sea una regla de decisión dependiente de un umbral $\\tau\\in[0,1]$:\n",
    "$$\\hat{y}_{\\tau}(\\boldsymbol{x})=\\mathbb{I}(p(y=1\\mid\\boldsymbol{x})\\geq 1-\\tau)$$\n",
    "Según la teoria de la decisión Bayesiana, la minimización del riesgo esperado conduce a la elección de un valor para $\\tau$; por ejemplo, $\\tau=0.5$ con pérdida 01. Ahora bien, si variamos $\\tau$ de $0$ a $1$, podemos estudiar el comportamiento del riesgo con más detalle. Por ejemplo, si $\\tau=0$ (quizás $-\\epsilon$), nunca clasificamos en la clase positiva, por lo que siempre fallamos con positivos y acertamos con negativos. Por el contrario, si $\\tau=1$, siempre clasificamos en la clase positiva, por lo que siempre acertamos con positivos y fallamos con negativos. Aparte del $\\tau$ de mínimo riesgo o de estos valores extremos, podemos encontrar valores de $\\tau$ que resulten interesantes en la tarea considerada. Un buen ejemplo para tener en mente en este contexto consiste en asumir que $\\boldsymbol{x}$ es el resultado de una prueba médica a partir de la cual se quiere confirmar o no un diagnóstico dado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices de confusión"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamamos **matriz de confusión (de clase)** a la matriz $K$ $2\\times 2$ en la que $K_{ij}$ es el número de veces que una muestra de la clase $i$ se \"confunde\" como perteneciente a la clase $j$; obviamente, si $i=j$ no se trata de confusión, sino de acierto, mientras que, si $i\\neq j$, sí se trata de una confusión o error de clasificación. Cada elemento de la matriz recibe un nombre específico:\n",
    "<div align=\"center\">\n",
    "\n",
    "|           |                  $\\hat{0}$ |                  $\\hat{1}$ |             Suma fila |\n",
    "|:---------:|:--------------------------:|:--------------------------:|:---------------------:|\n",
    "|         0 | $\\operatorname{TN}_{\\tau}$ | $\\operatorname{FP}_{\\tau}$ |                   $N$ |\n",
    "|         1 | $\\operatorname{FN}_{\\tau}$ | $\\operatorname{TP}_{\\tau}$ |                   $P$ |\n",
    "| **Suma:** |                  $\\hat{N}$ |                  $\\hat{P}$ | $\\hat{N}+\\hat{P}=N+P$ |\n",
    "\n",
    "</div>\n",
    "\n",
    "* $\\operatorname{TN}_{\\tau}$ es el número de **true negatives**\n",
    "* $\\operatorname{FP}_{\\tau}$ es el número de **false positives**\n",
    "* $\\operatorname{FN}_{\\tau}$ es el número de **false negatives**\n",
    "* $\\operatorname{TP}_{\\tau}$ es el número de **true positives**\n",
    "* $P$ y $\\hat{P}$ son los números verdadero y predicho de positivos\n",
    "* $N$ y $\\hat{N}$ son los números verdadero y predicho de negativos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **matriz de confusión normalizada por filas** produce (una estimación empírica de) $p(\\hat{y}\\mid y)$:\n",
    "<div align=\"center\">\n",
    "\n",
    "|              |                   $\\hat{0}$ |                   $\\hat{1}$ |             Suma fila |\n",
    "|:------------:|:---------------------------:|:---------------------------:|:---------------------:|\n",
    "|            0 | $\\operatorname{TNR}_{\\tau}$ | $\\operatorname{FPR}_{\\tau}$ |                 $1.0$ |\n",
    "|            1 | $\\operatorname{FNR}_{\\tau}$ | $\\operatorname{TPR}_{\\tau}$ |                 $1.0$ |\n",
    "\n",
    "</div>\n",
    "\n",
    "* $\\operatorname{TNR}_{\\tau}=\\operatorname{TN}_{\\tau}/N$ es el **true negative (rate)** o **specificity**\n",
    "* $\\operatorname{FPR}_{\\tau}=\\operatorname{FP}_{\\tau}/N$ es el **false positive (rate), false alarm, type I error** o **fallout**\n",
    "* $\\operatorname{FNR}_{\\tau}=\\operatorname{FN}_{\\tau}/P$ es el **false negative (rate), miss** o **type II error**\n",
    "* $\\operatorname{TPR}_{\\tau}=\\operatorname{TP}_{\\tau}/P$ es el **true positive (rate), hit, recall** o **sensitivity**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **matriz de confusión normalizada por columnas** produce (una estimación empírica de) $p(y\\mid \\hat{y})$:\n",
    "<div align=\"center\">\n",
    "\n",
    "|           |                   $\\hat{0}$ |                   $\\hat{1}$ |\n",
    "|:---------:|:---------------------------:|:---------------------------:|\n",
    "|         0 | $\\operatorname{NPV}_{\\tau}$ | $\\operatorname{FDR}_{\\tau}$ |\n",
    "|         1 | $\\operatorname{FOR}_{\\tau}$ | $\\operatorname{PPV}_{\\tau}$ |\n",
    "| **Suma:** |                       $1.0$ |                       $1.0$ |\n",
    "\n",
    "</div>\n",
    "\n",
    "* $\\operatorname{NPV}_{\\tau}=\\operatorname{TN}_{\\tau}/\\hat{N}$ es el **negative predictive value**\n",
    "* $\\operatorname{FOR}_{\\tau}=\\operatorname{FN}_{\\tau}/\\hat{N}$ es el **false omission rate**\n",
    "* $\\operatorname{FDR}_{\\tau}=\\operatorname{FP}_{\\tau}/\\hat{P}$ es el **false discovery rate**\n",
    "* $\\operatorname{PPV}_{\\tau}=\\operatorname{TP}_{\\tau}/\\hat{P}$ es el **positive predictive value** o **precision**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las matrices de confusión no se limitan a problemas de clasificación binaria y, de hecho, su uso en problemas de clasificación multi-clase es habitual. Si tenemos $C$ clases, $\\mathcal{Y}=\\{1,2,\\dotsc,C\\}$, llamamos **matriz de confusión (multi-clase)** a la matriz $K$ $C\\times C$ en la que $K_{ij}$ es el número de veces que una muestra de la clase $i$ se \"confunde\" como perteneciente a la clase $j$; al igual que en el caso binario, los elementos de la diagonal son aciertos, mientras que los elementos de fuera de la diagonal son confusiones propiamente dichas (errores). Consideremos una matriz de confusión calculada tras clasificar $M$ muestras:\n",
    "<div align=\"center\">\n",
    "\n",
    "|           | $\\hat{1}$ | $\\hat{2}$ |  $\\cdots$ | $\\hat{C}$ |  Suma fila |\n",
    "|:---------:|:---------:|:---------:|:---------:|:---------:|:----------:|\n",
    "|         1 | $M_{1,1}$ | $M_{1,2}$ |  $\\cdots$ | $M_{1,C}$ |  $M_{1,:}$ |\n",
    "|         2 | $M_{2,1}$ | $M_{2,2}$ |  $\\cdots$ | $M_{2,C}$ |  $M_{2,:}$ |\n",
    "|  $\\vdots$ |  $\\vdots$ |  $\\vdots$ |  $\\vdots$ |  $\\vdots$ |   $\\vdots$ |\n",
    "|         C | $M_{C,1}$ | $M_{C,2}$ |  $\\cdots$ | $M_{C,C}$ |  $M_{C,:}$ |\n",
    "| **Suma:** | $M_{:,1}$ | $M_{:,2}$ |  $\\cdots$ | $M_{:,C}$ |        $M$ |\n",
    "\n",
    "</div>\n",
    "\n",
    "Como en el caso binario, la matriz de confusión multi-clase puede normalizarse por filas, $p(\\hat{y}\\mid y)$, o por columnas, $p(y\\mid\\hat{y})$. No obstante, se suele normalizar por $N$ para producir una estimación empírica de $p(y, \\hat{y})$ que nos ayude a identificar qué pares de clases se confunden más. Por otro lado, si se quiere estudiar en detalle alguna clase espcífica, podemos considerarla como clase positiva de un problema de clasificación binario en el que las otras clases se consideran conjuntamente como clase negativa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvas ROC y resumen con un escalar\n",
    "\n",
    "Llamamos **curva Receiver Operating Characteristic (ROC)** a la gráfica que muestra la $\\operatorname{TPR}_{\\tau}$ en función de la $\\operatorname{FPR}_{\\tau}$ para $\\tau$ de $0$ a $1$:\n",
    "<div align=\"center\"><img width=\"500\" src=\"ROChand.png\"></div>\n",
    "\n",
    "En la esquina inferior izquierda tenemos $\\operatorname{TPR}_0=\\operatorname{FPR}_0=0$ mientras que, en la superior derecha, $\\operatorname{TPR}_1=\\operatorname{FPR}_1=1$. Un clasificador aleatorio uniforme, esto es, tal que $p(y=1\\mid\\boldsymbol{x})=\\operatorname{Unif}(0, 1)$, produce una curva ROC diagonal:\n",
    "$$\\begin{align*}\n",
    "\\operatorname{TPR}_{\\tau}&=\\frac{\\operatorname{TP}_{\\tau}}{P}=\\frac{P\\cdot\\tau}{P}=\\tau\\\\\n",
    "\\operatorname{FPR}_{\\tau}&=\\frac{\\operatorname{FP}_{\\tau}}{N}=\\frac{N\\cdot\\tau}{N}=\\tau\n",
    "\\end{align*}$$\n",
    "Obviamente, cabe esperar que nuestros clasificadores exhiban curvas ROC claramente por encima de la diagonal. Idealmente, un clasificador \"perfecto\" asigna $p(y=1\\mid\\boldsymbol{x})=1$ a todas las muestras positivas; $0$ a las negativas. Luego, su curva ROC es en realidad una recta que va de la esquina superior izquierda ($\\tau=0$) a la superior derecha ($\\tau=1$):\n",
    "$$\\begin{align*}\n",
    "\\operatorname{TPR}_0&=\\frac{\\operatorname{TP}_0}{P}=\\frac{P}{P}=1&&&\n",
    "\\operatorname{TPR}_1&=\\frac{\\operatorname{TP}_1}{P}=\\frac{P}{P}=1\\\\\n",
    "\\operatorname{FPR}_0&=\\frac{\\operatorname{FP}_0}{N}=\\frac{0}{N}=0&&&\n",
    "\\operatorname{FPR}_1&=\\frac{\\operatorname{FP}_1}{N}=\\frac{N}{N}=0%\n",
    "\\end{align*}$$\n",
    "La calidad de una curva ROC suele resumirse mediante algún escalar para facilitar su comparación con otras curvas. Por lo general se emplea el **área bajo la curva (AUC, area under curve)**; por ejemplo, el área azul para el clasificador B de la figura. Una alternativa a la AUC es el **equal error rate (EER)** o **cross-over rate**, definido como el valor de $\\tau$ en el que $\\operatorname{FPR}_{\\tau}=\\operatorname{FNR}_{\\tau}$. Como $\\operatorname{FNR}_{\\tau}=1-\\operatorname{FNR}_{\\tau}$, este valor viene dado por el punto en el que la curva ROC curva cruza la diagonal que va de la esquina superior izquierda a la inferior derecha. Por ejemplo, en la figura, se observa que la EER del A (rojo) es mejor (menor) que la del B (azul)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

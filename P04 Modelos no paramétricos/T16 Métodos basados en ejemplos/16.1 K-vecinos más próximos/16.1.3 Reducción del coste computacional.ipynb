{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducción del coste computacional\n",
    "\n",
    "Los clasificadores KNN se caracterizan por un elevado coste computacional, tanto espacial como temporal, debido al mantenimiento de (todos) los datos de entrenamiento en inferencia. Con el fin de reducir el coste espacial, se han propuesto diversas técnicas que, en esencia, eliminan prototipos (datos de entrenamiento) que no afectan a las fronteras de decisión. Por otro lado, para atacar el coste temporal, se han desarrollado numerosas técnicas de búsqueda eficiente de K vecinos, exacta y aproximada (para $D>10$), entre las que podemos destacar:\n",
    "* **K-d tree:** divide el espacio en regiones de lados paralelos a los ejes, o con algún método de clustering basado en puntos ancla.\n",
    "* **Locality sensitive hashing (LSH):** técnica popular de 1999; más recientemente se aprende la función de hashing.\n",
    "\n",
    "Una librería popular para la búsqueda eficiente de vecinos es [**FAISS.**](https://github.com/facebookresearch/faiss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

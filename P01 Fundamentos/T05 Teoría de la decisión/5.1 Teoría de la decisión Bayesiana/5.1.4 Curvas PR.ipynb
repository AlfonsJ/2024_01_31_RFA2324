{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curvas PR\n",
    "\n",
    "Las **curvas precision-recall (PR)** se usan para evaluar sistemas cuando conviene prestar especial atención a positivos ya que la noción de \"negativo\" no está bien definida. Por ejemplo, en detección de objetos en visión con patches, el número de verdaderos negativos depende del número de patches examinados. Otro ejemplo: en recuperación de información, el conjunto de negativos (documentos irrelevantes) depende del total de ítems recuperados. Tanto patches examinados como ítems recuperados son resultado de un algoritmo, no parte de la definición del problema."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de la precisión y cobertura\n",
    "\n",
    "La **precisión** se define como la fracción de positivos predichos que son verdad:\n",
    "$$\\mathcal{P}(\\tau)%\n",
    "=\\frac{\\operatorname{TP}_{\\tau}}{\\operatorname{TP}_{\\tau}+\\operatorname{FP}_{\\tau}}%\n",
    "=\\operatorname{PPV}_{\\tau}$$\n",
    "El **recall (cobertura)** es la fracción de positivos de verdad que son predichos:\n",
    "$$\\mathcal{R}(\\tau)%\n",
    "=\\frac{\\operatorname{TP}_{\\tau}}{\\operatorname{TP}_{\\tau}+\\operatorname{FN}_{\\tau}}=\\operatorname{TPR}_{\\tau}$$\n",
    "Llamamos **curva precision-recall (PR)** a la gráfica que muestra $\\mathcal{P}(\\tau)$ en función de $\\mathcal{R}(\\tau)$ para $\\tau$ de $0$ a $1$:\n",
    "<div align=\"center\"><img width=\"500\" src=\"PRhand.png\"></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En la esquina superior izquierda tenemos $\\mathcal{R}(0)=0$ y $\\mathcal{P}(0)=1$, esto es, nunca clasificamos en la clase positiva; eso sí, convenimos que, si no hemos hecho ninguna predicción positiva errónea, la precisión es máxima. En la esquina inferior derecha tenemos $\\mathcal{R}(1)=1$ y $\\mathcal{P}(1)$ próxima a $0$ pues siempre clasificamos en la clase positiva y asumimos que su peso relativo es muy pequeño. La curva PR de un clasificador \"perfecto\", que asigna $p(y=1\\mid\\boldsymbol{x})=1$ a todas las muestras positivas y $0$ a las negativas, es en realidad una recta que va de la esquina superior izquierda ($\\tau=0$) a la superior derecha ($\\tau=1$). En general, una curva PR será tanto mejor cuanto más se acerce a la esquina superior derecha."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.4.1 Atención como búsqueda suave en diccionario\n",
    "\n",
    "**Atención como búsqueda suave en diccionario:**\n",
    "<div><table><tr>\n",
    "<td style=\"border: none; text-align:left; vertical-align:top;\" width=450>\n",
    "\n",
    "Comparamos la query $\\boldsymbol{q}$ con cada key $\\boldsymbol{k}_i$ y recuperamos el valor correspondiente $\\boldsymbol{v}_i$. Para hacer la búsqueda diferenciable, en lugar de recuperar un único valor, combinamos los valores linealmente:\n",
    "$$\\operatorname{Attn}(\\boldsymbol{q},(\\boldsymbol{k}_{1:m},\\boldsymbol{v}_{1:m}))=\\sum_{i=1}^m\\alpha_i(\\boldsymbol{q},\\boldsymbol{k}_{1:m})\\boldsymbol{v}_i\\in\\mathbb{R}^v$$\n",
    "\n",
    "Los **pesos de atención** $\\,\\{\\alpha_i(\\boldsymbol{q},\\boldsymbol{k}_{1:m})\\}\\,$ se hallan con una función **score de atención** $a(\\boldsymbol{q},\\boldsymbol{k}_i)$ que mide la similitud de la query $\\boldsymbol{q}$ con cada key $\\boldsymbol{k}_i$\n",
    "$$\\alpha_i(\\boldsymbol{q},\\boldsymbol{k}_{1:m})=\\mathcal{S}_i([a(\\boldsymbol{q},\\boldsymbol{k}_1),\\dotsc,a(\\boldsymbol{q},\\boldsymbol{k}_m)])=\\frac{\\exp(a(\\boldsymbol{q},\\boldsymbol{k}_i))}{\\sum_{j=1}^m\\exp(a(\\boldsymbol{q},\\boldsymbol{k}_j))}$$\n",
    "cumpliéndose que\n",
    "$$0\\leq\\alpha_i(\\boldsymbol{q},\\boldsymbol{k}_{1:m})\\leq 1\\quad\\text{y}\\quad\\sum_i\\alpha_i(\\boldsymbol{q},\\boldsymbol{k}_{1:m})=1$$\n",
    "\n",
    "</td><td style=\"border: none;\"><img src=\"Figure_15.16.png\" width=\"550\"/></td>\n",
    "</tr></table></div>\n",
    "\n",
    "**Masked attention:** $\\;$ si queremos restringir la atención a un subconjunto del diccionario, podemos fijar el score de atención de las entradas a ignorar (\"masked out\") con un valor negativo grande ($-10^6$)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

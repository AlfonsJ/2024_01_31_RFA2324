{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo: MLP para clasificación de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrada:** $\\;$ secuencia de palabras de longitud variable, $\\boldsymbol{v}_1,\\ldots,\\boldsymbol{v}_T$\n",
    "* $\\boldsymbol{v}_t$ es un vector one-hot de dimensión igual a la talla del vocabulario, $V$\n",
    "* La secuencia se trata como una bolsa de palabras, $\\{\\boldsymbol{v}_t\\}$\n",
    "\n",
    "**Capa 1:** $\\;$ matriz de embedding $E\\times V$, $\\mathbf{W}_1$, que convierte cada vector disperso $\\boldsymbol{v}_t$ en uno denso $\\boldsymbol{e}_t$\n",
    "$$\\boldsymbol{e}_t=\\mathbf{W}_1\\boldsymbol{v}_t$$\n",
    "\n",
    "**Capa 2:** $\\;$ convierte la entrada en un único vector $E$-dimensional mediante **global average pooling**\n",
    "$$\\bar{\\boldsymbol{e}}=\\frac{1}{T}\\sum\\nolimits_{t=1}^T\\boldsymbol{e}_t$$\n",
    "\n",
    "**Resto:** $\\;$ MLP con una capa oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 16)          160000    \n",
      "                                                                 \n",
      " global_average_pooling1d_1  (None, 16)                0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160289 (626.13 KB)\n",
      "Trainable params: 160289 (626.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; import tensorflow as tf; from tensorflow import keras\n",
    "num_words = 10000; embed_size = 16\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=num_words)\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, value=0, padding=\"post\", maxlen=256)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, value=0, padding=\"post\", maxlen=256)\n",
    "tf.random.set_seed(42); np.random.seed(42)\n",
    "model = keras.Sequential([keras.layers.Embedding(num_words, embed_size),\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss: 0.3790019452571869 - accuracy: 86.7%\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "x_val = x_train[:10000]; x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]; y_train = y_train[10000:]\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=512, validation_data=(x_val, y_val), verbose=0)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test: loss: {score[0]} - accuracy: {score[1]:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

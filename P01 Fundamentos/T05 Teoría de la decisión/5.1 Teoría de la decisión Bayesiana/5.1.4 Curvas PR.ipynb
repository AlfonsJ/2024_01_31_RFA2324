{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curvas PR\n",
    "\n",
    "Las **curvas precision-recall (PR)** se usan para evaluar sistemas cuando conviene prestar especial atención a positivos ya que la noción de \"negativo\" no está bien definida. Por ejemplo, en detección de objetos en visión con patches, el número de verdaderos negativos depende del número de patches examinados. Otro ejemplo: en recuperación de información, el conjunto de negativos (documentos irrelevantes) depende del total de ítems recuperados. Tanto patches examinados como ítems recuperados son resultado de un algoritmo, no parte de la definición del problema."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precisión, cobertura y curva PR\n",
    "\n",
    "La **precisión** se define como la fracción de positivos predichos que son verdad:\n",
    "$$\\mathcal{P}(\\tau)%\n",
    "=\\frac{\\operatorname{TP}_{\\tau}}{\\operatorname{TP}_{\\tau}+\\operatorname{FP}_{\\tau}}%\n",
    "=\\frac{\\operatorname{TP}_{\\tau}}{\\hat{P}_{\\tau}}=\\operatorname{PPV}_{\\tau}$$\n",
    "El **recall (cobertura)** es la fracción de positivos de verdad que son predichos:\n",
    "$$\\mathcal{R}(\\tau)%\n",
    "=\\frac{\\operatorname{TP}_{\\tau}}{\\operatorname{TP}_{\\tau}+\\operatorname{FN}_{\\tau}}%\n",
    "=\\frac{\\operatorname{TP}_{\\tau}}{P}=\\operatorname{TPR}_{\\tau}$$\n",
    "Llamamos **curva precision-recall (PR)** a la gráfica de $\\mathcal{P}(\\tau)$ en función de $\\mathcal{R}(\\tau)$, obtenida al variar $\\tau$ de $0$ a $1$:\n",
    "<div align=\"center\"><img width=\"500\" src=\"PRhand.png\"></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las curvas PR de la figura son solo ejemplos de curvas PR que cabe esperar en la práctica; en teoría, sin embargo, las curvas PR pueden resultar muy distintas. Por ejemplo, de un clasificador aleatorio uniforme, $p(y=1\\mid\\boldsymbol{x})=\\operatorname{Unif}(0, 1)$, cabe esperar una curva PR horizontal a la altura de la fracción de positivos reconocidos:\n",
    "$$\\begin{align*}\n",
    "\\mathcal{R}(\\tau)&%\n",
    "=\\frac{\\operatorname{TP}_{\\tau}}{P}\\approx\\frac{P\\cdot\\tau}{P}=\\tau\\\\\n",
    "\\mathcal{P}(\\tau)&%\n",
    "=\\frac{\\operatorname{TP}_{\\tau}}{\\hat{P}_{\\tau}}\\approx\\frac{P\\cdot\\tau}{M\\cdot\\tau}=\\frac{P}{M}\n",
    "\\end{align*}$$\n",
    "Obviamente, es de esperar que nuestros clasificadores exhiban curvas PR claramente por encima de dicha horizontal. En general, cabe esperar curvas monótonamente decrecientes, como las de la figura, con el matiz de que la precisión para $\\tau=1$ (recall $1$) no es nula, sino $P/M$. Ahora bien, a diferencia de un curva ROC, cuyo comportamiento es siempre monótono (creciente), una curva PR puede exhibir un comportamiento no monótono (decreciente). Concretamente, si $\\tau'\\leq\\tau$, entonces se cumple que $\\mathcal{R}(\\tau')\\leq\\mathcal{R}(\\tau)$ pero puede ocurrir que $\\mathcal{P}(\\tau')>\\mathcal{P}(\\tau)$ si, por ejemplo, todos los nuevos positivos predichos entre $\\tau'$ y $\\tau$ son falsos positivos. Un clasificador \"perfecto\", de probabilidades $1$ para muestras positivas y $0$ para negativas, exhibirá una curva PR horizontal de precisión máxima salvo en $\\tau=1$ (recall $1$), donde caerá abruptamente a precisión $P/M$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen mediante un escalar\n",
    "\n",
    "Al igual que una curva ROC, la calidad de una curva PR suele resumirse mediante algún escalar para facilitar su comparación con otras curvas. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

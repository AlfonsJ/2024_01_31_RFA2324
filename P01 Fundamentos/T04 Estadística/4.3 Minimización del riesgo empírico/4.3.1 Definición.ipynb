{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición\n",
    "\n",
    "Empirical risk minimization (ERM) generaliza MLE sustituyendo la log-pérdida, \n",
    "$\\ell(\\boldsymbol{y}_n, \\boldsymbol{\\theta}; \\boldsymbol{x}_n)%\n",
    "=-\\log p(\\boldsymbol{y}_n\\mid\\boldsymbol{x}_n, \\boldsymbol{\\theta})$, \n",
    "por una pérdida genérica:\n",
    "$$\\hat{\\boldsymbol{\\theta}}_{\\text{erm}}=\\operatorname*{argmin}_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta})%\n",
    "\\quad\\text{con}\\quad%\n",
    "\\mathcal{L}(\\boldsymbol{\\theta})%\n",
    "=\\frac{1}{N}\\sum_{n=1}^N\\ell(\\boldsymbol{y}_n, \\boldsymbol{\\theta}; \\boldsymbol{x}_n)$$\n",
    "En clasificación es usual considerar la **pérdida 01** de un clasificador $f(\\boldsymbol{x}_n; \\boldsymbol{\\theta}):$\n",
    "$$\\ell_{01}(\\boldsymbol{y}_n, \\boldsymbol{\\theta}; \\boldsymbol{x}_n)%\n",
    "=\\begin{cases}\n",
    "  0 & \\text{si $\\boldsymbol{y}_n=f(\\boldsymbol{x}_n; \\boldsymbol{\\theta}$})\\\\%\n",
    "  1 & \\text{si $\\boldsymbol{y}_n\\neq f(\\boldsymbol{x}_n;\\boldsymbol{\\theta})$}%\n",
    "\\end{cases}$$\n",
    "Así, el riesgo empírico se reduce al **error de clasificación** (en entrenamiento):\n",
    "$$\\mathcal{L}_{01}(\\boldsymbol{\\theta})%\n",
    "=\\frac{1}{N}\\sum_{n=1}^N\\ell_{01}(\\boldsymbol{y}_n, \\boldsymbol{\\theta}; \\boldsymbol{x}_n)$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

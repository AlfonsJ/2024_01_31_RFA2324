{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.7.2 El algoritmo EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algoritmo expectation maximization (EM):** $\\;$ algoritmo de optimización acotada para calcular el estimador MLE o MAP de modelos probabilísticos con **datos perdidos** o **variables ocultas**\n",
    "\n",
    "**Notación:** $\\;$ para cada dato $n$, $\\boldsymbol{y}_n$ denota su parte observada y $\\boldsymbol{z}_n$ su parte perdida u oculta\n",
    "\n",
    "**Algoritmo EM básico:** $\\;$ repetir los siguientes dos pasos\n",
    "* **Paso E (expectation):** $\\;$ estimación de datos perdidos\n",
    "* **Paso M (maximization):** $\\;$ cálculo del MLE o MAP a partir de los datos completos\n",
    "\n",
    "**Convergencia:** $\\;$ veremos que el paso E calcula una función sustituta del objetivo, por lo que el EM converge a un màximo local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.2.1 Cota inferior\n",
    "\n",
    "**Objetivo:** $\\;$ maximizar la log-verosimilitud de los datos observados\n",
    "$$\\operatorname{LL}(\\boldsymbol{\\theta})=\\sum_{n=1}^N\\log p(\\boldsymbol{y}_n\\mid\\boldsymbol{\\theta})%\n",
    "=\\sum_{n=1}^N\\log\\left[\\sum_{\\boldsymbol{z}_n}p(\\boldsymbol{y}_n,\\boldsymbol{z}_n\\mid\\boldsymbol{\\theta})\\right]$$\n",
    "\n",
    "**Dificultad:** $\\;$ difícil de optimizar a causa del logaritmo delante del sumatorio\n",
    "\n",
    "**Evidence lower bound (ELBO):** $\\;$ dado un conjunto de distribuciones arbitrarias sobre cada $\\boldsymbol{z}_n$, $q_n(\\boldsymbol{z}_n)$, la **desigualdad de Jensen** permite construir una función $\\mathbf{Ł}(\\boldsymbol{\\theta},q_{1:N})$ cota inferior de la log-verosimilitud marginal o evidencia\n",
    "$$\\begin{align*}\n",
    "\\operatorname{LL}(\\boldsymbol{\\theta})%\n",
    "&=\\log p(\\boldsymbol{y}_{1:N}\\mid\\boldsymbol{\\theta})\\\\%\n",
    "&=\\sum_{n=1}^N\\log\\left[%\n",
    "\\sum_{\\boldsymbol{z}_n}q_n(\\boldsymbol{z}_n)\\,\\frac{p(\\boldsymbol{y}_n,\\boldsymbol{z}_n\\mid\\boldsymbol{\\theta})}{q_n(\\boldsymbol{z}_n)}\\right]\\\\%\n",
    "&\\geq\\sum_{n=1}^N\\sum_{\\boldsymbol{z}_n}q_n(\\boldsymbol{z}_n)\\log%\n",
    "\\frac{p(\\boldsymbol{y}_n,\\boldsymbol{z}_n\\mid\\boldsymbol{\\theta})}{q_n(\\boldsymbol{z}_n)}\\\\%\n",
    "&=\\sum_n\\underbrace{\\mathbb{E}_{q_n}[\\log p(\\boldsymbol{y}_n,\\boldsymbol{z}_n\\mid\\boldsymbol{\\theta})]+\\mathbb{H}(q_n)}%\n",
    "_{\\mathbf{Ł}(\\boldsymbol{\\theta},q_n\\mid\\boldsymbol{y}_n)}\\\\[3mm]%\n",
    "&=\\sum_n\\mathbf{Ł}(\\boldsymbol{\\theta},q_n)=\\mathbf{Ł}(\\boldsymbol{\\theta},\\{q_n\\})%\n",
    "=\\mathbf{Ł}(\\boldsymbol{\\theta},q_{1:N})%\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.2.2 Paso E\n",
    "\n",
    "**Paso E:** $\\;$ cálculo de $\\,q_n^*=p(\\boldsymbol{z}_n\\mid\\boldsymbol{y}_n,\\boldsymbol{\\theta})\\,$ y, así, $\\,\\mathbf{Ł}(\\boldsymbol{\\theta},q_n^*)=\\log p(\\boldsymbol{y}_n\\mid\\boldsymbol{\\theta})$\n",
    "$$\\begin{align*}\n",
    "\\mathbf{Ł}&(\\boldsymbol{\\theta},q_n)%\n",
    "=\\sum_{\\boldsymbol{z}_n}q_n(\\boldsymbol{z}_n)\\log\\frac{p(\\boldsymbol{y}_n,\\boldsymbol{z}_n\\mid\\boldsymbol{\\theta})}{q_n(\\boldsymbol{z}_n)}\\\\%\n",
    "&=\\sum_{\\boldsymbol{z}_n}q_n(\\boldsymbol{z}_n)\\log%\n",
    "\\frac{p(\\boldsymbol{z}_n\\mid\\boldsymbol{y}_n,\\boldsymbol{\\theta})\\,p(\\boldsymbol{y}_n\\mid\\boldsymbol{\\theta})}{q_n(\\boldsymbol{z}_n)}\\\\%\n",
    "&=\\sum_{\\boldsymbol{z}_n}q_n(\\boldsymbol{z}_n)\\log\\frac{p(\\boldsymbol{z}_n\\mid\\boldsymbol{y}_n,\\boldsymbol{\\theta})}{q_n(\\boldsymbol{z}_n)}%\n",
    "+\\sum_{\\boldsymbol{z}_n}q_n(\\boldsymbol{z}_n)\\log p(\\boldsymbol{y}_n\\mid\\boldsymbol{\\theta})\\\\%\n",
    "&=-\\mathbb{KL}(q_n(\\boldsymbol{z}_n)\\,\\Vert\\,p(\\boldsymbol{z}_n\\mid\\boldsymbol{y}_n,\\boldsymbol{\\theta}))%\n",
    "+\\log p(\\boldsymbol{y}_n\\mid\\boldsymbol{\\theta})\\\\%\n",
    "&\\overset{q_n=q_n^*}{=}\\log p(\\boldsymbol{y}_n\\mid\\boldsymbol{\\theta})%\n",
    "\\qquad(\\mathbb{KL}(q_n(\\boldsymbol{z}_n)\\,\\Vert\\,p(\\boldsymbol{z}_n\\mid\\boldsymbol{y}_n,\\boldsymbol{\\theta}))=0%\n",
    "\\quad\\text{sii}\\quad q_n= q_n^*=p(\\boldsymbol{z}_n\\mid\\boldsymbol{y}_n,\\boldsymbol{\\theta}))%\n",
    "\\end{align*}$$\n",
    "\n",
    "**Función sustituta:** $\\;$ dado que $\\;\\mathbf{Ł}(\\boldsymbol{\\theta},\\{q_n^*\\})=\\operatorname{LL}(\\boldsymbol{\\theta}),\\,$ la función\n",
    "$$Q(\\boldsymbol{\\theta},\\boldsymbol{\\theta}^{(t)})=\\mathbf{Ł}(\\boldsymbol{\\theta},\\{q_n^*=p(\\boldsymbol{z}_n\\mid\\boldsymbol{y}_n,\\boldsymbol{\\theta}^{(t)})\\})$$\n",
    "es ELBO por Jensen,\n",
    "$$Q(\\boldsymbol{\\theta},\\boldsymbol{\\theta}^{(t)})\\leq\\operatorname{LL}(\\boldsymbol{\\theta})$$\n",
    "y toca $\\operatorname{LL}(\\boldsymbol{\\theta})$ en $\\boldsymbol{\\theta}^{(t)}$ al tomar $\\{q_n^*=p(\\boldsymbol{z}_n\\mid\\boldsymbol{y}_n,\\boldsymbol{\\theta}^{(t)})\\}$,\n",
    "$$Q(\\boldsymbol{\\theta}^{(t)},\\boldsymbol{\\theta}^{(t)})=\\operatorname{LL}(\\boldsymbol{\\theta}^{(t)})$$\n",
    "\n",
    "**Paso E aproximado:** $\\;$ si el cálculo de $\\,q_n^*=p(\\boldsymbol{z}_n\\mid\\boldsymbol{y}_n,\\boldsymbol{\\theta})$ es muy costoso, podemos emplear una aproximación a la misma y la $Q$, aunque menos ajustada, sigue siendo ELBO\n",
    "* **Aproximación directa:** $\\;$ comprobamos que la $\\operatorname{LL}$ no decrece; cosa quizás sencilla si solo consideramos distribuciones delta\n",
    "* **EM variacional:** $\\;$ EM generalizado en marco Bayesiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.2.3 Paso M\n",
    "\n",
    "**Expected complete data log likelihood:** $\\;$ el paso M maximiza $\\,\\mathbf{Ł}(\\boldsymbol{\\theta},\\{q_n^{(t)}\\})\\,$ con respecto a $\\boldsymbol{\\theta}$, donde las $\\,\\{q_n^{(t)}\\}\\,$ son las distribuciones halladas en el paso E de la iteración $t$; ahora bien, los términos de entropía $\\,\\mathbb{H}(q_n)\\,$ pueden ignorarse porque no dependen de $\\boldsymbol{\\theta}$\n",
    "$$\\operatorname{LL}^{(t)}(\\boldsymbol{\\theta})=\\sum_n\\mathbb{E}_{q_n^{(t)}(\\boldsymbol{z}_n)}[\\log p(\\boldsymbol{y}_n,\\boldsymbol{z}_n\\mid\\boldsymbol{\\theta})]$$\n",
    "\n",
    "**Caso (conjunta de la) familia exponencial:** $\\;$ no necesitamos $\\,\\{q_n^{(t)}\\};\\;$ bastan estadísticos suficientes esperados, $\\,\\mathbb{E}[\\mathcal{T}(\\boldsymbol{y}_n,\\boldsymbol{z}_n)]$,\n",
    "$$\\operatorname{LL}^{(t)}(\\boldsymbol{\\theta})%\n",
    "=\\sum_n\\mathbb{E}[\\mathcal{T}(\\boldsymbol{y}_n,\\boldsymbol{z}_n)^{(t)}\\boldsymbol{\\theta}-A(\\boldsymbol{\\theta})]%\n",
    "=\\sum_n(\\mathbb{E}[\\mathcal{T}(\\boldsymbol{y}_n,\\boldsymbol{z}_n)]^{(t)}-A(\\boldsymbol{\\theta}))$$\n",
    "\n",
    "**Paso M:** $\\;$ maximización de la log-verosimilitud completa esperada\n",
    "$$\\boldsymbol{\\theta}^{(t+1)}=\\operatorname*{argmax}\\limits_{\\boldsymbol{\\theta}}\\sum_n\\mathbb{E}_{q_n^{(t)}(\\boldsymbol{z}_n)}[\\log p(\\boldsymbol{y}_n,\\boldsymbol{z}_n\\mid\\boldsymbol{\\theta})]$$\n",
    "\n",
    "**Caso familia exponencial:** $\\;$ se resuelve en forma cerrada"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
